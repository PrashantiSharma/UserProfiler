{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPikJB7/630DtmPH+BC4nxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrashantiSharma/UserProfiler/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuIDkjDHzYsE",
        "outputId": "376ebfc1-2ef3-48bd-c810-39b1660edc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Reddit profile URL: https://www.reddit.com/user/Hungry-Move-6603/\n",
            "Error fetching Reddit data: Expecting value: line 1 column 1 (char 0)\n",
            "✅ Persona image saved: Hungry-Move-6603_persona.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------- IMPORTS -----------------\n",
        "import requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "import re\n",
        "\n",
        "# ----------------- FUNCTIONS -----------------\n",
        "\n",
        "# Extract username from Reddit profile URL\n",
        "def extract_username_from_url(url):\n",
        "    if \"reddit.com/user/\" in url:\n",
        "        return url.rstrip('/').split('/')[-1]\n",
        "    raise ValueError(\"Invalid Reddit URL format\")\n",
        "\n",
        "# Fetch user's recent posts and comments\n",
        "def fetch_user_data(username):\n",
        "    headers = {'User-Agent': 'PersonaScript/1.0'}\n",
        "    posts_url = f\"https://www.reddit.com/user/{username}/submitted.json\"\n",
        "    comments_url = f\"https://www.reddit.com/user/{username}/comments.json\"\n",
        "\n",
        "    try:\n",
        "        posts = requests.get(posts_url, headers=headers).json().get('data', {}).get('children', [])\n",
        "        comments = requests.get(comments_url, headers=headers).json().get('data', {}).get('children', [])\n",
        "        return posts, comments\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching Reddit data:\", e)\n",
        "        return [], []\n",
        "\n",
        "def extract_persona(username, posts, comments):\n",
        "    texts = [p['data'].get('selftext') or p['data'].get('title') or '' for p in posts]\n",
        "    texts += [c['data'].get('body') or '' for c in comments]\n",
        "    combined = \" \".join(texts).lower()\n",
        "\n",
        "    # Age\n",
        "    age_match = re.search(r\"\\b(i'?m|i am|turned)\\s+(\\d{2})\\b\", combined)\n",
        "    age = f\"{age_match.group(2)} years old\" if age_match else \"Unknown\"\n",
        "\n",
        "    # Occupation\n",
        "    occupation_match = re.search(r\"i\\s+(am|work as|work at|do)\\s+(a|an)?\\s?([\\w\\s\\-]+)\", combined)\n",
        "    occupation = occupation_match.group(3).strip() if occupation_match else \"Unknown\"\n",
        "\n",
        "    # Status\n",
        "    if any(word in combined for word in [\"girlfriend\", \"boyfriend\", \"wife\", \"husband\", \"partner\"]):\n",
        "        status = \"In a relationship\"\n",
        "    elif \"single\" in combined or \"divorced\" in combined:\n",
        "        status = \"Single\"\n",
        "    else:\n",
        "        status = \"Unknown\"\n",
        "\n",
        "    # Location\n",
        "    location_match = re.search(r\"i (live|am from|grew up) in ([a-zA-Z ,]+)\", combined)\n",
        "    location = location_match.group(2).title() if location_match else \"Unknown\"\n",
        "\n",
        "    # Behavior\n",
        "    behavior = [f\"- {text.strip()[:150]}...\" for text in texts if len(text.strip()) > 60][:5]\n",
        "\n",
        "    # Frustrations (naive: look for negatives)\n",
        "    frustrations = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"hate\", \"can't\", \"annoy\", \"frustrated\", \"bad\", \"problem\"])][:3]\n",
        "\n",
        "    # Goals (intent)\n",
        "    goals = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"want to\", \"hope\", \"goal\", \"try to\", \"plan to\"])][:3]\n",
        "\n",
        "    # Quote\n",
        "    quote = max(texts, key=len) if texts else f\"I'm {username}, and I enjoy Reddit.\"\n",
        "\n",
        "    return {\n",
        "        \"name\": username.capitalize(),\n",
        "        \"age\": age,\n",
        "        \"occupation\": occupation,\n",
        "        \"status\": status,\n",
        "        \"location\": location,\n",
        "        \"tier\": \"Inferred\",\n",
        "        \"archetype\": \"The Observer\",\n",
        "        \"traits\": [\"Inquisitive\", \"Expressive\", \"Authentic\", \"Reflective\"],\n",
        "        \"motivations\": {\n",
        "            \"Convenience\": 50 + len(goals)*10,\n",
        "            \"Wellness\": 30 + len([g for g in goals if \"health\" in g])*30,\n",
        "            \"Speed\": 60,\n",
        "            \"Preferences\": 40,\n",
        "            \"Comfort\": 50,\n",
        "            \"Dietary Needs\": 20\n",
        "        },\n",
        "        \"personality\": {\n",
        "            \"Introvert\": 50,\n",
        "            \"Extrovert\": 50,\n",
        "            \"Intuition\": 60,\n",
        "            \"Sensing\": 40,\n",
        "            \"Feeling\": 55,\n",
        "            \"Thinking\": 45,\n",
        "            \"Perceiving\": 50,\n",
        "            \"Judging\": 50\n",
        "        },\n",
        "        \"behavior\": behavior if behavior else [\"- No meaningful behavior found.\"],\n",
        "        \"frustrations\": frustrations if frustrations else [\"- No frustrations detected.\"],\n",
        "        \"goals\": goals if goals else [\"- No clear goals mentioned.\"],\n",
        "        \"quote\": quote[:200]\n",
        "    }\n",
        "\n",
        "# Draw persona image\n",
        "def build_persona_image(persona, output_path=\"reddit_persona.png\"):\n",
        "    img = Image.new('RGB', (1200, 800), color='white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    import matplotlib.font_manager as fm\n",
        "\n",
        "    # Fallback font path\n",
        "    default_font = fm.findfont(fm.FontProperties(family='DejaVu Sans'))\n",
        "    title_font = ImageFont.truetype(default_font, 32)\n",
        "    section_font = ImageFont.truetype(default_font, 22)\n",
        "    text_font = ImageFont.truetype(default_font, 18)\n",
        "    # Draw basic info\n",
        "    draw.text((450, 20), persona[\"name\"], fill=\"orange\", font=title_font)\n",
        "    fields = [\"age\", \"occupation\", \"status\", \"location\", \"tier\", \"archetype\"]\n",
        "    for i, field in enumerate(fields):\n",
        "        label = field.upper()\n",
        "        value = persona[field]\n",
        "        draw.text((450, 70 + i * 30), f\"{label}: {value}\", fill=\"black\", font=text_font)\n",
        "\n",
        "    # Traits\n",
        "    for i, trait in enumerate(persona[\"traits\"]):\n",
        "        draw.rectangle([(450 + (i % 2) * 120, 260 + (i // 2) * 40),\n",
        "                        (560 + (i % 2) * 120, 290 + (i // 2) * 40)], fill=\"#eee\")\n",
        "        draw.text((455 + (i % 2) * 120, 265 + (i // 2) * 40), trait, font=text_font, fill=\"black\")\n",
        "\n",
        "    # Section headers\n",
        "    draw.text((50, 320), \"BEHAVIOUR & HABITS\", fill=\"black\", font=section_font)\n",
        "    draw.text((650, 320), \"FRUSTRATIONS\", fill=\"black\", font=section_font)\n",
        "\n",
        "    # Behavior & frustrations\n",
        "    for i, line in enumerate(persona[\"behavior\"]):\n",
        "        draw.text((50, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "    for i, line in enumerate(persona[\"frustrations\"]):\n",
        "        draw.text((650, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    # Goals\n",
        "    draw.text((50, 530), \"GOALS & NEEDS\", fill=\"black\", font=section_font)\n",
        "    for i, goal in enumerate(persona[\"goals\"]):\n",
        "        draw.text((50, 570 + i * 24), f\"• {goal}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    # Quote box\n",
        "    draw.rectangle([(30, 700), (1170, 780)], fill=\"orange\")\n",
        "    wrapped_quote = textwrap.fill(f'\"{persona[\"quote\"]}\"', width=80)\n",
        "    draw.text((40, 720), wrapped_quote, font=text_font, fill=\"white\")\n",
        "\n",
        "    # Save\n",
        "    img.save(output_path)\n",
        "    print(f\"✅ Persona image saved: {output_path}\")\n",
        "\n",
        "# ----------------- MAIN EXECUTION -----------------\n",
        "\n",
        "# Input Reddit profile URL\n",
        "input_url = input(\"Enter Reddit profile URL: \").strip()\n",
        "username = extract_username_from_url(input_url)\n",
        "\n",
        "# Fetch and build persona\n",
        "posts, comments = fetch_user_data(username)\n",
        "persona = extract_persona(username, posts, comments)\n",
        "\n",
        "# Create image\n",
        "build_persona_image(persona, output_path=f\"{username}_persona.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (run once)\n",
        "!pip install pillow requests\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTXr9buCzcvk",
        "outputId": "04e8bbb2-8249-4899-fc97-d05426cd45c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.9)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.94.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "import re\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# ----------------- FUNCTIONS -----------------\n",
        "\n",
        "def extract_username_from_url(url):\n",
        "    if \"reddit.com/user/\" in url:\n",
        "        return url.rstrip('/').split('/')[-1]\n",
        "    raise ValueError(\"Invalid Reddit URL format\")\n",
        "\n",
        "def fetch_user_data(username):\n",
        "    headers = {'User-Agent': 'PersonaScript/1.0'}\n",
        "    posts_url = f\"https://www.reddit.com/user/{username}/submitted.json\"\n",
        "    comments_url = f\"https://www.reddit.com/user/{username}/comments.json\"\n",
        "    try:\n",
        "        posts = requests.get(posts_url, headers=headers).json().get('data', {}).get('children', [])\n",
        "        comments = requests.get(comments_url, headers=headers).json().get('data', {}).get('children', [])\n",
        "        return posts, comments\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching Reddit data:\", e)\n",
        "        return [], []\n",
        "\n",
        "def fetch_user_icon(username):\n",
        "    headers = {'User-Agent': 'PersonaScript/1.0'}\n",
        "    about_url = f\"https://www.reddit.com/user/{username}/about.json\"\n",
        "    try:\n",
        "        response = requests.get(about_url, headers=headers).json()\n",
        "        return response['data'].get('icon_img', None)\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching Reddit profile icon:\", e)\n",
        "        return None\n",
        "\n",
        "def download_image(url, filename=\"avatar.png\"):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(\"Image download failed:\", e)\n",
        "        return None\n",
        "\n",
        "def extract_persona(username, posts, comments):\n",
        "    texts = [p['data'].get('selftext') or p['data'].get('title') or '' for p in posts]\n",
        "    texts += [c['data'].get('body') or '' for c in comments]\n",
        "    combined = \" \".join(texts).lower()\n",
        "\n",
        "    age_match = re.search(r\"\\b(i'?m|i am|turned)\\s+(\\d{2})\\b\", combined)\n",
        "    age = f\"{age_match.group(2)} years old\" if age_match else \"Unknown\"\n",
        "\n",
        "    occupation_match = re.search(r\"i\\s+(am|work as|work at|do)\\s+(a|an)?\\s?([\\w\\s\\-]+)\", combined)\n",
        "    occupation = occupation_match.group(3).strip() if occupation_match else \"Unknown\"\n",
        "\n",
        "    if any(word in combined for word in [\"girlfriend\", \"boyfriend\", \"wife\", \"husband\", \"partner\"]):\n",
        "        status = \"In a relationship\"\n",
        "    elif \"single\" in combined or \"divorced\" in combined:\n",
        "        status = \"Single\"\n",
        "    else:\n",
        "        status = \"Unknown\"\n",
        "\n",
        "    location_match = re.search(r\"i (live|am from|grew up) in ([a-zA-Z ,]+)\", combined)\n",
        "    location = location_match.group(2).title() if location_match else \"Unknown\"\n",
        "\n",
        "    behavior = [f\"- {text.strip()[:150]}...\" for text in texts if len(text.strip()) > 60][:5]\n",
        "    frustrations = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"hate\", \"can't\", \"annoy\", \"frustrated\", \"bad\", \"problem\"])][:3]\n",
        "    goals = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"want to\", \"hope\", \"goal\", \"try to\", \"plan to\"])][:3]\n",
        "    quote = max(texts, key=len) if texts else f\"I'm {username}, and I enjoy Reddit.\"\n",
        "\n",
        "    return {\n",
        "        \"name\": username.capitalize(),\n",
        "        \"age\": age,\n",
        "        \"occupation\": occupation,\n",
        "        \"status\": status,\n",
        "        \"location\": location,\n",
        "        \"tier\": \"Inferred\",\n",
        "        \"archetype\": \"The Observer\",\n",
        "        \"traits\": [\"Inquisitive\", \"Expressive\", \"Authentic\", \"Reflective\"],\n",
        "        \"motivations\": {\n",
        "            \"Convenience\": 50 + len(goals)*10,\n",
        "            \"Wellness\": 30 + len([g for g in goals if \"health\" in g])*30,\n",
        "            \"Speed\": 60,\n",
        "            \"Preferences\": 40,\n",
        "            \"Comfort\": 50,\n",
        "            \"Dietary Needs\": 20\n",
        "        },\n",
        "        \"personality\": {\n",
        "            \"Introvert\": 50,\n",
        "            \"Extrovert\": 50,\n",
        "            \"Intuition\": 60,\n",
        "            \"Sensing\": 40,\n",
        "            \"Feeling\": 55,\n",
        "            \"Thinking\": 45,\n",
        "            \"Perceiving\": 50,\n",
        "            \"Judging\": 50\n",
        "        },\n",
        "        \"behavior\": behavior if behavior else [\"- No meaningful behavior found.\"],\n",
        "        \"frustrations\": frustrations if frustrations else [\"- No frustrations detected.\"],\n",
        "        \"goals\": goals if goals else [\"- No clear goals mentioned.\"],\n",
        "        \"quote\": quote[:200]\n",
        "    }\n",
        "from openai import OpenAI\n",
        "\n",
        "def analyze_with_llm(combined_text):\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following Reddit content, summarize the user's persona:\n",
        "    {combined_text[:3000]}\n",
        "\n",
        "    Output format:\n",
        "    - Age:\n",
        "    - Occupation:\n",
        "    - Status:\n",
        "    - Location:\n",
        "    - Traits:\n",
        "    - Frustrations:\n",
        "    - Goals:\n",
        "    - Motivations:\n",
        "    - Personality (MBTI-style):\n",
        "    - Quote:\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(...)  # or other provider\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "def extract_persona_llm(username, posts, comments):\n",
        "    texts = [p['data'].get('selftext') or p['data'].get('title') or '' for p in posts]\n",
        "    texts += [c['data'].get('body') or '' for c in comments]\n",
        "    combined = \" \".join(texts)\n",
        "\n",
        "    if len(combined.strip()) < 200:\n",
        "        print(\"🛑 Not enough content for LLM. Falling back to regex.\")\n",
        "        return extract_persona(username, posts, comments)\n",
        "\n",
        "    try:\n",
        "        return analyze_with_llm(username, combined)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ LLM analysis failed:\", e)\n",
        "        return extract_persona(username, posts, comments)\n",
        "\n",
        "\n",
        "def build_persona_image(persona, output_path=\"reddit_persona.png\"):\n",
        "    img = Image.new('RGB', (1200, 800), color='white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    default_font = fm.findfont(fm.FontProperties(family='DejaVu Sans'))\n",
        "    title_font = ImageFont.truetype(default_font, 32)\n",
        "    section_font = ImageFont.truetype(default_font, 22)\n",
        "    text_font = ImageFont.truetype(default_font, 18)\n",
        "\n",
        "    try:\n",
        "        avatar = Image.open(\"avatar.png\").resize((120, 120))\n",
        "        img.paste(avatar, (300, 20))\n",
        "    except Exception as e:\n",
        "        print(\"Couldn't paste avatar:\", e)\n",
        "\n",
        "    draw.text((450, 20), persona[\"name\"], fill=\"orange\", font=title_font)\n",
        "    fields = [\"age\", \"occupation\", \"status\", \"location\", \"tier\", \"archetype\"]\n",
        "    for i, field in enumerate(fields):\n",
        "        label = field.upper()\n",
        "        value = persona[field]\n",
        "        draw.text((450, 70 + i * 30), f\"{label}: {value}\", fill=\"black\", font=text_font)\n",
        "\n",
        "    for i, trait in enumerate(persona[\"traits\"]):\n",
        "        draw.rectangle([(450 + (i % 2) * 120, 260 + (i // 2) * 40), (560 + (i % 2) * 120, 290 + (i // 2) * 40)], fill=\"#eee\")\n",
        "        draw.text((455 + (i % 2) * 120, 265 + (i // 2) * 40), trait, font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.text((50, 320), \"BEHAVIOUR & HABITS\", fill=\"black\", font=section_font)\n",
        "    draw.text((650, 320), \"FRUSTRATIONS\", fill=\"black\", font=section_font)\n",
        "    for i, line in enumerate(persona[\"behavior\"]):\n",
        "        draw.text((50, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "    for i, line in enumerate(persona[\"frustrations\"]):\n",
        "        draw.text((650, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.text((50, 530), \"GOALS & NEEDS\", fill=\"black\", font=section_font)\n",
        "    for i, goal in enumerate(persona[\"goals\"]):\n",
        "        draw.text((50, 570 + i * 24), f\"• {goal}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.rectangle([(30, 700), (1170, 780)], fill=\"orange\")\n",
        "    wrapped_quote = textwrap.fill(f'\"{persona[\"quote\"]}\"', width=80)\n",
        "    draw.text((40, 720), wrapped_quote, font=text_font, fill=\"white\")\n",
        "\n",
        "    img.save(output_path)\n",
        "    print(f\"✅ Persona image saved: {output_path}\")\n"
      ],
      "metadata": {
        "id": "szhDrUrY-Z7C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- MAIN EXECUTION -----------------\n",
        "if __name__ == \"__main__\":\n",
        "    input_url = input(\"Enter Reddit profile URL: \").strip()\n",
        "    username = extract_username_from_url(input_url)\n",
        "\n",
        "    # Fetch data\n",
        "    posts, comments = fetch_user_data(username)\n",
        "    persona = extract_persona(username, posts, comments)\n",
        "\n",
        "    # Fetch and download avatar\n",
        "    avatar_url = fetch_user_icon(username)\n",
        "    if avatar_url:\n",
        "        download_image(avatar_url, filename=\"avatar.png\")\n",
        "\n",
        "    # Generate persona image\n",
        "    build_persona_image(persona, output_path=f\"{username}_persona.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS8PJoSA_uAY",
        "outputId": "87a8cb21-d6d3-4a28-df6c-c9685dd4ada1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Reddit profile URL: https://www.reddit.com/user/PracticeOk817/\n",
            "Error fetching Reddit data: Expecting value: line 1 column 1 (char 0)\n",
            "Error fetching Reddit profile icon: Expecting value: line 1 column 1 (char 0)\n",
            "Couldn't paste avatar: [Errno 2] No such file or directory: 'avatar.png'\n",
            "✅ Persona image saved: PracticeOk817_persona.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full working Reddit Persona Generator using Reddit OAuth (option 2)\n",
        "\n",
        "import requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "import re\n",
        "import os\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# ----------------- CONFIG -----------------\n",
        "REDDIT_CLIENT_ID = 'jAjrDWn9twXmy5aQg9GYbA'\n",
        "REDDIT_CLIENT_SECRET = '2RQFOOTtorNwOJJQsEeLQ-11lK2ZGQ'\n",
        "REDDIT_USERNAME = 'PracticeOk817'\n",
        "REDDIT_PASSWORD = 'YOUR_REDDIT_PASSWORD'\n",
        "USER_AGENT = 'PersonaBuilder/0.1 by u/PracticeOk817'\n",
        "\n",
        "# ----------------- AUTHENTICATION -----------------\n",
        "def get_reddit_access_token():\n",
        "    auth = requests.auth.HTTPBasicAuth(REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET)\n",
        "    data = {\n",
        "        'grant_type': 'password',\n",
        "        'username': REDDIT_USERNAME,\n",
        "        'password': REDDIT_PASSWORD\n",
        "    }\n",
        "    headers = {'User-Agent': USER_AGENT}\n",
        "    res = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=auth, data=data, headers=headers)\n",
        "    res.raise_for_status()\n",
        "    token = res.json()['access_token']\n",
        "    return {'Authorization': f'bearer {token}', 'User-Agent': USER_AGENT}\n",
        "\n",
        "# ----------------- FUNCTIONS -----------------\n",
        "def extract_username_from_url(url):\n",
        "    if \"reddit.com/user/\" in url:\n",
        "        return url.rstrip('/').split('/')[-1]\n",
        "    raise ValueError(\"Invalid Reddit URL format\")\n",
        "\n",
        "def fetch_user_data(username, headers):\n",
        "    try:\n",
        "        posts = requests.get(f\"https://oauth.reddit.com/user/{username}/submitted\", headers=headers).json().get('data', {}).get('children', [])\n",
        "        comments = requests.get(f\"https://oauth.reddit.com/user/{username}/comments\", headers=headers).json().get('data', {}).get('children', [])\n",
        "        return posts, comments\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching Reddit data:\", e)\n",
        "        return [], []\n",
        "\n",
        "def fetch_user_icon(username, headers):\n",
        "    try:\n",
        "        response = requests.get(f\"https://oauth.reddit.com/user/{username}/about\", headers=headers).json()\n",
        "        return response['data'].get('icon_img', None)\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching Reddit profile icon:\", e)\n",
        "        return None\n",
        "\n",
        "def download_image(url, filename=\"avatar.png\"):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(\"Image download failed:\", e)\n",
        "        return None\n",
        "\n",
        "def extract_persona(username, posts, comments):\n",
        "    texts = [p['data'].get('selftext') or p['data'].get('title') or '' for p in posts]\n",
        "    texts += [c['data'].get('body') or '' for c in comments]\n",
        "    combined = \" \".join(texts).lower()\n",
        "\n",
        "    age_match = re.search(r\"\\b(i'?m|i am|turned)\\s+(\\d{2})\\b\", combined)\n",
        "    age = f\"{age_match.group(2)} years old\" if age_match else \"Unknown\"\n",
        "\n",
        "    occupation_match = re.search(r\"i\\s+(am|work as|work at|do)\\s+(a|an)?\\s?([\\w\\s\\-]+)\", combined)\n",
        "    occupation = occupation_match.group(3).strip() if occupation_match else \"Unknown\"\n",
        "\n",
        "    if any(word in combined for word in [\"girlfriend\", \"boyfriend\", \"wife\", \"husband\", \"partner\"]):\n",
        "        status = \"In a relationship\"\n",
        "    elif \"single\" in combined or \"divorced\" in combined:\n",
        "        status = \"Single\"\n",
        "    else:\n",
        "        status = \"Unknown\"\n",
        "\n",
        "    location_match = re.search(r\"i (live|am from|grew up) in ([a-zA-Z ,]+)\", combined)\n",
        "    location = location_match.group(2).title() if location_match else \"Unknown\"\n",
        "\n",
        "    behavior = [f\"- {text.strip()[:150]}...\" for text in texts if len(text.strip()) > 60][:5]\n",
        "    frustrations = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"hate\", \"can't\", \"annoy\", \"frustrated\", \"bad\", \"problem\"])][:3]\n",
        "    goals = [f\"- {text.strip()[:100]}...\" for text in texts if any(word in text for word in [\"want to\", \"hope\", \"goal\", \"try to\", \"plan to\"])][:3]\n",
        "    quote = max(texts, key=len) if texts else f\"I'm {username}, and I enjoy Reddit.\"\n",
        "\n",
        "    return {\n",
        "        \"name\": username.capitalize(),\n",
        "        \"age\": age,\n",
        "        \"occupation\": occupation,\n",
        "        \"status\": status,\n",
        "        \"location\": location,\n",
        "        \"tier\": \"Inferred\",\n",
        "        \"archetype\": \"The Observer\",\n",
        "        \"traits\": [\"Inquisitive\", \"Expressive\", \"Authentic\", \"Reflective\"],\n",
        "        \"motivations\": {\n",
        "            \"Convenience\": 50 + len(goals)*10,\n",
        "            \"Wellness\": 30 + len([g for g in goals if \"health\" in g])*30,\n",
        "            \"Speed\": 60,\n",
        "            \"Preferences\": 40,\n",
        "            \"Comfort\": 50,\n",
        "            \"Dietary Needs\": 20\n",
        "        },\n",
        "        \"personality\": {\n",
        "            \"Introvert\": 50,\n",
        "            \"Extrovert\": 50,\n",
        "            \"Intuition\": 60,\n",
        "            \"Sensing\": 40,\n",
        "            \"Feeling\": 55,\n",
        "            \"Thinking\": 45,\n",
        "            \"Perceiving\": 50,\n",
        "            \"Judging\": 50\n",
        "        },\n",
        "        \"behavior\": behavior if behavior else [\"- No meaningful behavior found.\"],\n",
        "        \"frustrations\": frustrations if frustrations else [\"- No frustrations detected.\"],\n",
        "        \"goals\": goals if goals else [\"- No clear goals mentioned.\"],\n",
        "        \"quote\": quote[:200]\n",
        "    }\n",
        "\n",
        "def build_persona_image(persona, output_path=\"reddit_persona.png\"):\n",
        "    img = Image.new('RGB', (1200, 800), color='white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    default_font = fm.findfont(fm.FontProperties(family='DejaVu Sans'))\n",
        "    title_font = ImageFont.truetype(default_font, 32)\n",
        "    section_font = ImageFont.truetype(default_font, 22)\n",
        "    text_font = ImageFont.truetype(default_font, 18)\n",
        "\n",
        "    try:\n",
        "        avatar = Image.open(\"avatar.png\").resize((120, 120))\n",
        "        img.paste(avatar, (300, 20))\n",
        "    except Exception as e:\n",
        "        print(\"Couldn't paste avatar:\", e)\n",
        "\n",
        "    draw.text((450, 20), persona[\"name\"], fill=\"orange\", font=title_font)\n",
        "    fields = [\"age\", \"occupation\", \"status\", \"location\", \"tier\", \"archetype\"]\n",
        "    for i, field in enumerate(fields):\n",
        "        label = field.upper()\n",
        "        value = persona[field]\n",
        "        draw.text((450, 70 + i * 30), f\"{label}: {value}\", fill=\"black\", font=text_font)\n",
        "\n",
        "    for i, trait in enumerate(persona[\"traits\"]):\n",
        "        draw.rectangle([(450 + (i % 2) * 120, 260 + (i // 2) * 40), (560 + (i % 2) * 120, 290 + (i // 2) * 40)], fill=\"#eee\")\n",
        "        draw.text((455 + (i % 2) * 120, 265 + (i // 2) * 40), trait, font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.text((50, 320), \"BEHAVIOUR & HABITS\", fill=\"black\", font=section_font)\n",
        "    draw.text((650, 320), \"FRUSTRATIONS\", fill=\"black\", font=section_font)\n",
        "    for i, line in enumerate(persona[\"behavior\"]):\n",
        "        draw.text((50, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "    for i, line in enumerate(persona[\"frustrations\"]):\n",
        "        draw.text((650, 360 + i * 24), f\"{line}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.text((50, 530), \"GOALS & NEEDS\", fill=\"black\", font=section_font)\n",
        "    for i, goal in enumerate(persona[\"goals\"]):\n",
        "        draw.text((50, 570 + i * 24), f\"• {goal}\", font=text_font, fill=\"black\")\n",
        "\n",
        "    draw.rectangle([(30, 700), (1170, 780)], fill=\"orange\")\n",
        "    wrapped_quote = textwrap.fill(f'\"{persona[\"quote\"]}\"', width=80)\n",
        "    draw.text((40, 720), wrapped_quote, font=text_font, fill=\"white\")\n",
        "\n",
        "    img.save(output_path)\n",
        "    print(f\"✅ Persona image saved: {output_path}\")\n"
      ],
      "metadata": {
        "id": "wH5UQtn6Ma-G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    input_url = input(\"Enter Reddit profile URL: \").strip()\n",
        "    username = extract_username_from_url(input_url)\n",
        "\n",
        "    headers = get_reddit_access_token()\n",
        "    posts, comments = fetch_user_data(username, headers)\n",
        "    persona = extract_persona(username, posts, comments)\n",
        "\n",
        "    icon_url = fetch_user_icon(username, headers)\n",
        "    if icon_url:\n",
        "        download_image(icon_url, \"avatar.png\")\n",
        "\n",
        "    build_persona_image(persona, output_path=f\"{username}_persona.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "1fKy_r39McSa",
        "outputId": "8dcb9c71-f63e-497a-c640-d1c262293919"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Reddit profile URL: https://www.reddit.com/user/Hungry-Move-6603/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'access_token'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-3060501677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_username_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reddit_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpersona\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_persona\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-1591738354.py\u001b[0m in \u001b[0;36mget_reddit_access_token\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.reddit.com/api/v1/access_token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'access_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf'bearer {token}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'access_token'"
          ]
        }
      ]
    }
  ]
}